{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.feature import hog\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.utils import np_utils\n",
    "import seaborn as sns\n",
    "from keras.applications.inception_v3 import preprocess_input, InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_DIR = '/content/celeba-dataset/'\n",
    "IMAGES = MAIN_DIR + 'img_align_celeba/img_align_celeba/'\n",
    "\n",
    "#variables\n",
    "IMG_WIDTH = 178\n",
    "IMG_HEIGHT = 218\n",
    "IMG_SHAPE = (IMG_WIDTH, IMG_HEIGHT, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the data set that include the attribute for each picture\n",
    "attributes = pd.read_csv(MAIN_DIR + 'list_attr_celeba.csv')\n",
    "# set the index to the first column\n",
    "attributes.set_index('image_id', inplace=True)\n",
    "#replace -1 with 0\n",
    "attributes.replace(to_replace=[-1], value=0, inplace=True)\n",
    "attributes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# available attributes\n",
    "attributes.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample picture with the attributes\n",
    "image_sample = load_img(IMAGES + '000001.jpg', target_size=(IMG_WIDTH, IMG_HEIGHT))\n",
    "plt.imshow(image_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count of the number of female and male\n",
    "plt.title('Count of Male and female')\n",
    "sns.countplot(y='Male', data=attributes, color=\"c\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load recommended partitions\n",
    "partitions = pd.read_csv(MAIN_DIR+'list_eval_partition.csv')\n",
    "partitions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display count by partition where\n",
    "# 0 -> TRAINING\n",
    "# 1 -> VALIDATION\n",
    "# 2 -> TEST\n",
    "\n",
    "partitions['partition'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join the partirions with the attributes\n",
    "partitions.set_index('image_id', inplace=True)\n",
    "partitions_attributes = partitions.join(attributes['Male'], how='inner')\n",
    "partitions_attributes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load reshape image\n",
    "\n",
    "def load_reshape_img(fname):\n",
    "    img = load_img(fname)\n",
    "    x = img_to_array(img)/255.\n",
    "    x = x.reshape((1,) + x.shape)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def generate_df(partition, attr, num_samples):\n",
    "    \n",
    "    df_ = partitions_attributes[(partitions_attributes['partition'] == partition) \n",
    "                           & (partitions_attributes[attr] == 0)].sample(int(num_samples/2))\n",
    "    df_ = pd.concat([df_,\n",
    "                      partitions_attributes[(partitions_attributes['partition'] == partition) \n",
    "                                  & (partitions_attributes[attr] == 1)].sample(int(num_samples/2))])\n",
    "\n",
    "    # for Train and Validation\n",
    "    if partition != 2:\n",
    "        x_ = np.array([load_reshape_img(IMAGES + fname) for fname in df_.index])\n",
    "        x_ = x_.reshape(x_.shape[0], 218, 178, 3)\n",
    "        y_ = np_utils.to_categorical(df_[attr],2)\n",
    "    # for Test\n",
    "    else:\n",
    "        x_ = []\n",
    "        y_ = []\n",
    "\n",
    "        for index, target in df_.iterrows():\n",
    "            im = cv2.imread(IMAGES + index)\n",
    "            im = cv2.resize(cv2.cvtColor(im, cv2.COLOR_BGR2RGB), (IMG_WIDTH, IMG_WIDTH)).astype(np.float32) / 255.0\n",
    "            im = np.expand_dims(im, axis =0)\n",
    "            x_.append(im)\n",
    "            y_.append(target[attr])\n",
    "\n",
    "    return x_, y_\n",
    "\n",
    "    # generate dataframe for training, validation and test set as well as the labels\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate image generator for data augmentation\n",
    "datagen =  ImageDataGenerator(\n",
    "  #preprocessing_function=preprocess_input,\n",
    "  rotation_range=30,\n",
    "  width_shift_range=0.2,\n",
    "  height_shift_range=0.2,\n",
    "  shear_range=0.2,\n",
    "  zoom_range=0.2,\n",
    "  horizontal_flip=True\n",
    ")\n",
    "\n",
    "# the datagen generates batches of images and labels, ImageDataGenerator is a generator which is a library for data augmentation\n",
    "# Data augmentation is a process of randomly changing the appearance of an image so that it can be used as a training example.\n",
    "\n",
    "# load one image and reshape\n",
    "img = load_img(IMAGES + '000001.jpg')\n",
    "x = img_to_array(img)/255.\n",
    "x = x.reshape((1,) + x.shape)\n",
    "\n",
    "# plot 10 augmented images of the loaded iamge\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.suptitle('Data Augmentation', fontsize=28)\n",
    "\n",
    "i = 0\n",
    "for batch in datagen.flow(x, batch_size=1):\n",
    "    plt.subplot(3, 5, i+1)\n",
    "    plt.grid(False)\n",
    "    plt.imshow( batch.reshape(218, 178, 3))\n",
    "    \n",
    "    if i == 9:\n",
    "        break\n",
    "    i += 1\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data\n",
    "x_train, y_train = generate_df(0, 'Male', 8000)\n",
    "\n",
    "# Training,  Data Preparationm  Data Augmentation with generators\n",
    "train_datagen =  ImageDataGenerator(\n",
    "  preprocessing_function=preprocess_input,\n",
    "  rotation_range=30,\n",
    "  width_shift_range=0.2,\n",
    "  height_shift_range=0.2,\n",
    "  shear_range=0.2,\n",
    "  zoom_range=0.2,\n",
    "  horizontal_flip=True,\n",
    ")\n",
    "\n",
    "train_datagen.fit(x_train)\n",
    "\n",
    "train_generator = train_datagen.flow(\n",
    "x_train, y_train,\n",
    "batch_size=16,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation Data\n",
    "x_valid, y_valid = generate_df(1, 'Male', 2000)\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_138019/1986051211.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGlobalAveragePooling2D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# checkpointer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.models import Sequential, Model \n",
    "# checkpointer\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "inception_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "\n",
    "# Used inception model which is pretrained on imagenet dataset to extract features from the images, then used it to train a new model\n",
    "\"\"\"\n",
    "The InceptionV3 model is a deep convolutional neural network model with success rate of >99% on the ImageNet dataset.\n",
    "It has been used for image classification tasks and is one of the most popular models for image classification. Here we use the InceptionV3 model to extract features from the images.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# add custom layers\n",
    "\n",
    "x = inception_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "predictions = Dense(2, activation='softmax')(x)\n",
    "\n",
    "\n",
    "\n",
    "# create the model\n",
    "\n",
    "\"\"\"\n",
    "create the model using the inception model as the base model and add custom layers on top of it.\n",
    "\n",
    "\"\"\"\n",
    "model = Model(inputs=inception_model.input, outputs=predictions)\n",
    "\n",
    "# freeze the layers\n",
    "\"\"\" \n",
    "Freezing the layers of the inception model is a technique used to prevent the model from overfitting.\n",
    "It is used to freeze the weights of the inception model and only train the top layers.\n",
    "\n",
    "\"\"\"\n",
    "for layer in inception_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model\n",
    "\"\"\"\n",
    "Compile the model using the rmsprop optimizer and categorical crossentropy loss function.\n",
    "RMSprop is a gradient descent algorithm which is used to minimize the loss function.\n",
    "Categorical crossentropy is a loss function used to measure the difference between the predicted output and the actual output.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# checkpointer\n",
    "\"\"\"\n",
    "Checkpoint is a callback which is used to save the model after every epoch.\n",
    "It is used to save the model after every epoch so that the model can be used to make predictions.\n",
    "\n",
    "\"\"\"\n",
    "checkpointer = ModelCheckpoint(filepath='model.{epoch:02d}.h5', verbose=1, save_best_only=True)\n",
    "\n",
    "# history\n",
    "\"\"\"\n",
    "\n",
    "History is a callback which is used to save the training and validation accuracy and loss after every epoch.\n",
    "It is used to plot the accuracy and loss after every epoch.\n",
    "\"\"\"\n",
    "history = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=10,\n",
    "        validation_data=(x_valid, y_valid),\n",
    "        callbacks=[checkpointer],\n",
    "        verbose=1\n",
    "        )\n",
    "\n",
    "# plot the training and validation loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# plot accuracy the training and validation accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# build another model, SVM classifier for the test data using HOG\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# HOG\n",
    "from skimage.feature import hog\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# get hog features\n",
    "\"\"\"\n",
    "get hog features from the test data\n",
    "HOG is a feature descriptor which is used to extract features from the images.\n",
    "How it works:\n",
    "1. Extract the HOG features from the images\n",
    "2. Scale the features\n",
    "\"\"\"\n",
    "def get_hog_features(img, orient, pix_per_cell, cell_per_block, vis=False, feature_vec=True):\n",
    "    if vis == True:\n",
    "        features, hog_image = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                                  cells_per_block=(cell_per_block, cell_per_block), block_norm='L2-Hys',\n",
    "                                  feature_vector=feature_vec)\n",
    "        return features, hog_image\n",
    "    else:\n",
    "        features = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                                  cells_per_block=(cell_per_block, cell_per_block), block_norm='L2-Hys',\n",
    "                                  feature_vector=feature_vec)\n",
    "        return features\n",
    "\n",
    "\n",
    "# use the HOG to extract features from the test data\n",
    "def extract_features(imgs, cspace='RGB', orient=9,\n",
    "                        pix_per_cell=8, cell_per_block=2, hog_channel=0):\n",
    "        features = []\n",
    "        for img in imgs:\n",
    "            if cspace != 'RGB':\n",
    "                if cspace == 'HSV':\n",
    "                    feature_image = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "                elif cspace == 'LUV':\n",
    "                    feature_image = cv2.cvtColor(img, cv2.COLOR_BGR2LUV)\n",
    "                elif cspace == 'HLS':\n",
    "                    feature_image = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "                elif cspace == 'YUV':\n",
    "                    feature_image = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)\n",
    "                elif cspace == 'YCrCb':\n",
    "                    feature_image = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
    "            else:\n",
    "                feature_image = np.copy(img)\n",
    "            # Call get_hog_features() with vis=False, feature_vec=True\n",
    "            if hog_channel == 'ALL':\n",
    "                hog_features = []\n",
    "                for channel in range(feature_image.shape[2]):\n",
    "                    hog_features.append(get_hog_features(feature_image[:,:,channel],\n",
    "                                        orient, pix_per_cell, cell_per_block,\n",
    "                                        vis=False, feature_vec=True))\n",
    "                hog_features = np.ravel(hog_features)\n",
    "            else:\n",
    "                hog_features = get_hog_features(feature_image[:,:,hog_channel], orient,\n",
    "                            pix_per_cell, cell_per_block, vis=False, feature_vec=True)\n",
    "            features.append(hog_features)\n",
    "        return np.array(features)\n",
    "\n",
    "        # extract features from the test data\n",
    "x_train_features = extract_features(x_train, cspace='YCrCb',\n",
    "                                    orient=9, pix_per_cell=8, cell_per_block=2, hog_channel='ALL')\n",
    "x_valid_features = extract_features(x_valid, cspace='YCrCb',\n",
    "                                    orient=9, pix_per_cell=8, cell_per_block=2, hog_channel='ALL')  \n",
    "\n",
    "\n",
    "# use the SVM classifier to classify the test data\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split the data into training and validation sets\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train_features, y_train, test_size=0.2, random_state=0)\n",
    "\n",
    "# define the parameters to search\n",
    "param_grid = {'C': [0.1, 1, 10, 100]}\n",
    "\n",
    "# create a pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('clf', LinearSVC())\n",
    "])\n",
    "\n",
    "# search for the best parameters\n",
    "grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=5, verbose=1)\n",
    "\n",
    "# fit the model\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# print the best parameters\n",
    "print('Best parameters: {}'.format(grid_search.best_params_))\n",
    "\n",
    "# print the best score\n",
    "print('Best score: {}'.format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "97cc609b13305c559618ec78a438abc56230b9381f827f22d070313b9a1f3777"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
