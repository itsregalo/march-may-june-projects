{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image classification using SVM\n",
    "\n",
    "# import the necessary packages\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 709/709 [00:07<00:00, 90.22it/s] \n"
     ]
    }
   ],
   "source": [
    "# training data path\n",
    "train_path = 'data/training'\n",
    "\n",
    "# testing data path\n",
    "test_path = 'data/testing'\n",
    "\n",
    "# get the training image paths\n",
    "train_image_paths = list(paths.list_images(train_path))\n",
    "\n",
    "# get the testing image paths\n",
    "test_image_paths = list(paths.list_images(test_path))\n",
    "\n",
    "# initialize the data and labels\n",
    "training_data = []\n",
    "training_labels = []\n",
    "\n",
    "# loop over the training images\n",
    "for image_path in tqdm(train_image_paths):\n",
    "    # load the image and extract the class label assuming\n",
    "    # that our path has the following format:\n",
    "    # /path/to/dataset/{class}/{image}.jpg\n",
    "    image = cv2.imread(image_path)\n",
    "    label = image_path.split(os.path.sep)[-2]\n",
    "\n",
    "    # resize the image to be a fixed 96x96 pixels, ignoring\n",
    "    # aspect ratio\n",
    "    image = cv2.resize(image, (96, 96))\n",
    "\n",
    "    # update the data and labels lists, respectively\n",
    "    training_data.append(image)\n",
    "    training_labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training data: 709\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] training data: {}\".format(len(training_data)))\n",
    "len_training_data = len(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(training_data).reshape(len_training_data, -1)\n",
    "y = np.array(training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(709, 27648)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.31764706, 0.31764706, 0.31764706, ..., 0.19215686, 0.19215686,\n",
       "       0.19215686])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#flatten the images\n",
    "X = X/255.0\n",
    "X[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(709,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array(y)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 267/267 [00:00<00:00, 360.96it/s]\n"
     ]
    }
   ],
   "source": [
    "testing_data = []\n",
    "testing_labels = []\n",
    "\n",
    "# loop over the testing images\n",
    "for image_path in tqdm(test_image_paths):\n",
    "    # load the image and extract the class label assuming\n",
    "    # that our path has the following format:\n",
    "    # /path/to/dataset/{class}/{image}.jpg\n",
    "    image = cv2.imread(image_path)\n",
    "    label = image_path.split(os.path.sep)[-2]\n",
    "\n",
    "    # resize the image to be a fixed 96x96 pixels, ignoring\n",
    "    # aspect ratio\n",
    "    image = cv2.resize(image, (96, 96))\n",
    "\n",
    "    # update the data and labels lists, respectively\n",
    "    testing_data.append(image)\n",
    "    testing_labels.append(label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(testing_data)\n",
    "len_testing_data = len(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data = np.array(testing_data).reshape(len_testing_data, -1)\n",
    "testing_labels = np.array(testing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00370627, 0.00370627, 0.00370627, ..., 0.00278354, 0.00278354,\n",
       "       0.00278354])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_data.shape\n",
    "testing_data = testing_data/255.0\n",
    "testing_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting the data to the model\n",
    "model = LinearSVC(C=100.0, random_state=42)\n",
    "model.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the testing data\n",
    "predictions = model.predict(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(testing_labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fromulating the Classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(testing_labels, predictions))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "13c4fa65054c0d3bfb9dbdc50fbf8af2a6ced466e99fd692bb576917c08ad093"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
